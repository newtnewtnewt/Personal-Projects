---
title: "HW07"
author: "Noah Dunn"
date: "November 17, 2018"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(GGally)
library(lindia)
library(ggfortify)
library(caret)
set.seed(66666)
```

###1.

```{r}
clintonData <- read.csv("election1992.csv")
clintonData <- clintonData %>%
  mutate(Q1 = quantile(Percent,0.25),
         Q3 = quantile(Percent,0.75))
cleanClintonData <- clintonData %>%
  filter(Percent > Q1 & Percent < Q3)
```

###2.

```{r}
clintonData$identifier <- 'notIQR'
cleanClintonData$identifier <- 'IQR'
graphData <- rbind(clintonData, cleanClintonData)
ggplot(graphData)+
  geom_density(aes(x=Percent, fill = identifier), alpha=0.5)+
  theme(legend.position="bottom")
```

For the plot that contains all the data, the density of percentage voting appears about normal with a large density conentration at around 40 Perceent with a Density close to 0.045. The IQR plot on the other hand has a very small range of percentages (35 ~ 45) with all the density falling in this range close to 0.085.

###3.

```{r}
full.fit <- lm(Percent ~ Age + Savings + Income + Poverty + Veterans + Female + Population + Nursing + Crime, data = cleanClintonData)
step.pick.backward <- step(full.fit, direction="backward")
summary(step.pick.backward)
```
set.seed(66666)
```{r} 
train_control <- trainControl(method="cv", number=10)
ptm <- proc.time()
train.choochoo <- train(Percent ~ Age + Savings + Income + Poverty + Veterans + Female + Population + Nursing + Crime, data= cleanClintonData, trControl=train_control, method="lm")


```

```{r}
train_control <- trainControl(method="cv", number=10)
train.choochoochoo <- train(Percent ~ Poverty + Veterans + Female + Population + Nursing + Crime + Age, data= cleanClintonData, trControl=train_control, method="lm")
print(proc.time() - ptm)
results10 <- resamples(list(Mod1 = train.choochoo, Mod2= train.choochoochoo ))
```

##4.

set.seed(66666)
```{r} 
train_control <- trainControl(method="cv", number=500)
ptm <- proc.time()
train.choochoo <- train(Percent ~ Age + Savings + Income + Poverty + Veterans + Female + Population + Nursing + Crime, data= cleanClintonData, trControl=train_control, method="lm")
```

```{r}
train_control <- trainControl(method="cv", number=500)
train.choochoochoo <- train(Percent ~ Poverty + Veterans + Female + Population + Nursing + Crime + Age, data= cleanClintonData, trControl=train_control, method="lm")
print(proc.time() - ptm)
results500 <- resamples(list(Mod1 = train.choochoo, Mod2= train.choochoochoo ))
```

##5.

```{r}
summary(results10)
summary(results500)
```
Although the 500 fold cross-validation takes almost 6 times longer than the 10 fold cross-validation, the R-Squared value for the particular seed I used on my particular machine went from around 0.06 for both models on the 10 fold validation to around 0.65 on the 500 fold validation. The 10 fold is much faster, but the 500 fold is a much more predictive model with a higher R-squared.  

##6.
Using my particular seed, the full model proved to have a higher R-Squared with the 10-fold, and the backwards-prediction model proved to have a higher R-Squared with the 500-fold.
However, given that it is likely one would want to use the fold technique with a much larger R-Squared output, the second model, or the model that selected according to backwards selection is likely preferable to the one that just included everything.

















